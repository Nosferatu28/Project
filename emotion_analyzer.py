# -*- coding: utf-8 -*-
"""Emotion_Analyzer

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Cypbu_cXeFqCaSFIzSp3iIoR8ER0RwRk
"""

import pandas as pd
import numpy as np
import nltk
import matplotlib.pyplot as plt
import seaborn as sns

from google.colab import files
data = files.upload()

from wordcloud import WordCloud
import re

import nltk
from nltk.tokenize import word_tokenize
from nltk.stem import PorterStemmer
from nltk.stem import WordNetLemmatizer
from nltk.corpus import wordnet

from sklearn.model_selection import train_test_split

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn import metrics


nltk.download('punkt')
nltk.download('wordnet')

import warnings
warnings.filterwarnings("ignore")

df = pd.read_csv("Emotion_classify_Data.csv")

df.head()

df['Emotion'].value_counts()

df = df[df['Emotion'] != 'fear'].reset_index(drop=True)
df['Emotion'].value_counts()

df.describe()

df.info()

anger = df[df['Emotion'] == 'anger']

text_anger = ''
for line in anger.Comment:
    text_anger += line + ' '

wordCloudAnger = WordCloud(background_color='white').generate(text_anger)
plt.imshow(wordCloudAnger)
plt.axis('off')
plt.show()

joy = df[df['Emotion'] == 'joy']

text_joy = ''
for line in joy.Comment:
    text_joy += line + ' '

wordCloudJoy = WordCloud(background_color='white').generate(text_joy)
plt.imshow(wordCloudJoy)
plt.axis('off')
plt.show()

df['num_characters'] = df['Comment'].str.len()

import nltk
nltk.download('punkt_tab')

df['num_sentences'] = df['Comment'].apply(lambda x: len(nltk.sent_tokenize(x)))
df['num_sentences'].value_counts()

# drop num_sentences
df.drop(['num_sentences'], axis=1, inplace=True)
df.head()

df['lowercase_comment'] = df['Comment'].str.lower()
df.head()

# function to remove patterns
def remove_patterns(text):
    # Remove URLs
    text = re.sub(r'http[s]?://\S+', '', text)
    # Remove markdown-style links
    text = re.sub(r'\[.*?\]\(.*?\)', '', text)
    # Remove handles (that start with '@')
    text = re.sub(r'@\w+', '', text)
    # Remove punctuation and other special characters
    text = re.sub(r'[^\w\s]', '', text)
    return text.strip()

df['lowercase_comment'] = df['lowercase_comment'].apply(remove_patterns)
df.head()

df['tokens'] = df['lowercase_comment'].apply(word_tokenize)
df.head()

text = df['Comment'][8]
text

"""'i was feeling at the start didnt want to move much at all was really glad to experience this glimpse into the sort of vibrant energy i will gain through out the year'"""

stemmer = PorterStemmer()

# we need to tokenize the text first
text_tokens = word_tokenize(text)
# text_tokens

stemmed_words = [stemmer.stem(word) for word in text_tokens]
stemmed_words

for word in zip(text_tokens, stemmed_words):
    print(word)

def get_pos(word):
    if word.startswith('J'):
        return wordnet.ADJ
    elif word.startswith('V'):
        return wordnet.VERB
    elif word.startswith('N'):
        return wordnet.NOUN
    elif word.startswith('R'):
        return wordnet.ADV
    else:
        return wordnet.NOUN

lemmatizer = WordNetLemmatizer()

def lemma_text(text_tokens):
    word_pos = nltk.pos_tag(text_tokens)
    lemmatized_words = [lemmatizer.lemmatize(wp[0], get_pos(wp[1])) for wp in word_pos]
    return lemmatized_words

nltk.download('averaged_perceptron_tagger_eng')
df['lemmatized_tokens'] = df['tokens'].apply(lemma_text)
df['lemmatized_tokens'] = df['lemmatized_tokens'].apply(lambda x: ' '.join(x)) # join back the tokens into a string
df.head(10)

anger_tokens = df[df['Emotion'] == 'anger']

text_anger = ''

for line in anger_tokens.lemmatized_tokens:
    text_anger += line + ' '

wordCloudAnger = WordCloud(background_color='white').generate(text_anger)
plt.imshow(wordCloudAnger)
plt.axis('off')
plt.show()

search_word = 'feeling'
result = df[df['lemmatized_tokens'].str.contains(search_word)]
print(len(result))
result.head()

s = df.iloc[16] # get the 16th row to check the pos tags

word_pos = nltk.pos_tag(s['tokens'])
word_pos

d = df.iloc[44]

word_pos = nltk.pos_tag(d['tokens'])
word_pos

joy_tokens = df[df['Emotion'] == 'anger']

text_joy = ''

for line in joy_tokens.lemmatized_tokens:
    text_joy += line + ' '

wordCloudJoy = WordCloud(background_color='white').generate(text_joy)
plt.imshow(wordCloudJoy)
plt.axis('off')
plt.show()

X = df['lemmatized_tokens']
y = df['Emotion']

y = y.map({'anger': 0, 'joy': 1})

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

X_train.shape, X_test.shape, y_train.shape, y_test.shape

vectorizer = TfidfVectorizer(ngram_range=(1, 2))
X_train_matrix = vectorizer.fit_transform(X_train)
X_test_matrix = vectorizer.transform(X_test)
y_train = np.array(y_train)
y_test = np.array(y_test)

C_list = [0.001, 0.01, 0.1, 1, 10, 100]
col_labels = ['C', 'Train AUC', 'Model Complexity - Coef Sum', 'Test AUC']

result_log_L2_arr = []
result_fpr_L2_arr = []
result_tpr_L2_arr = []

for c_value in C_list:
    result_log_L2_list = []


    # Building the model with the c value
    log_model_L2 = LogisticRegression(solver='liblinear', max_iter=1000, random_state=42, C=c_value, penalty='l2')
    log_model_L2.fit(X_train_matrix, y_train)

    # Check to make sure 1 is in the second column
    print('Class order: ', log_model_L2.classes_)
    if log_model_L2.classes_[1] == 1:
        print('Correct class selection')
    else:
        print('Incorrect class selection, check clases.')
     # Calculate the AUC for the training data
    y_train_pred_proba = log_model_L2.predict_proba(X_train_matrix)
    y_train_pred_proba_1 = y_train_pred_proba[:, 1]  # Only get the probability of class 3
    train_AUC = metrics.roc_auc_score(y_train, y_train_pred_proba_1)

    # Calculate the AUC for the test data
    y_test_pred_proba = log_model_L2.predict_proba(X_test_matrix)
    y_test_pred_proba_1 = y_test_pred_proba[:, 1]  # Only get the probability of class 3
    test_AUC = metrics.roc_auc_score(y_test, y_test_pred_proba_1)

    # Calculate fpr and tpr for the ROC curve
    fpr, tpr, thresholds = metrics.roc_curve(y_test, y_test_pred_proba_1, pos_label=1)

    # Compute complexity of the model
    complexity_coef_sum = np.sum(np.abs(log_model_L2.coef_))

    # Complie the results
    result_log_L2_list = [c_value, train_AUC, complexity_coef_sum, test_AUC]
    result_log_L2_arr.append(result_log_L2_list)
    result_fpr_L2_arr.append(list(fpr))
    result_tpr_L2_arr.append(list(tpr))


    print('C value', c_value)
    print('Model Complecity', complexity_coef_sum)
    print('Train AUC', train_AUC)
    print('Test AUC', test_AUC)
    print('-----------------------------------------')
    df_log_L2 = pd.DataFrame(result_log_L2_arr, columns=col_labels)
    df_log_L2

colours=['r','g','b','k','m','c']
plt.figure(figsize=(6, 6))
for i in range(len(result_fpr_L2_arr)):
    plt.plot(result_fpr_L2_arr[i], result_tpr_L2_arr[i], label='C = ' + str(C_list[i]), color=colours[i])
plt.legend(loc='lower right')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve')
plt.grid(True)
plt.show()

C_list = [0.001, 0.01, 0.1, 1, 10, 100]
col_labels = ['C', 'Train AUC', 'Model Complexity - Coef Sum', 'Test AUC']

result_log_L1_arr = []
result_fpr_L1_arr = []
result_tpr_L1_arr = []

for c_value in C_list:
    result_log_L1_list = []


    # Building the model with the c value
    log_model_L1 = LogisticRegression(solver='liblinear', max_iter=1000, random_state=42, C=c_value, penalty='l1')
    log_model_L1.fit(X_train_matrix, y_train)

    # Check to make sure 3 is in the second column
    print('Class order: ', log_model_L1.classes_)
    if log_model_L1.classes_[1] == 1:
        print('Correct class selection')
    else:
        print('Incorrect class selection, check clases.')

    # Calculate the AUC for the training data
    y_train_pred_proba = log_model_L1.predict_proba(X_train_matrix)
    y_train_pred_proba_1 = y_train_pred_proba[:, 1]  # Only get the probability of class 3
    train_AUC = metrics.roc_auc_score(y_train, y_train_pred_proba_1)

    # Calculate the AUC for the test data
    y_test_pred_proba = log_model_L1.predict_proba(X_test_matrix)
    y_test_pred_proba_1 = y_test_pred_proba[:, 1]  # Only get the probability of class 3
    test_AUC = metrics.roc_auc_score(y_test, y_test_pred_proba_1)

    # Calculate fpr and tpr for the ROC curve
    fpr, tpr, thresholds = metrics.roc_curve(y_test, y_test_pred_proba_1, pos_label=1)

    # Compute complexity of the model
    complexity_coef_sum = np.sum(np.abs(log_model_L1.coef_))

    # Complie the results
    result_log_L1_list = [c_value, train_AUC, complexity_coef_sum, test_AUC]
    result_log_L1_arr.append(result_log_L1_list)
    result_fpr_L1_arr.append(list(fpr))
    result_tpr_L1_arr.append(list(tpr))


    print('C value', c_value)
    print('Model Complecity', complexity_coef_sum)
    print('Train AUC', train_AUC)
    print('Test AUC', test_AUC)
    print('-----------------------------------------')

df_log_L1 = pd.DataFrame(result_log_L1_arr, columns=col_labels)
df_log_L1

colours=['r','g','b','k','m','c']
plt.figure(figsize=(6, 6))
for i in range(len(result_fpr_L1_arr)):
    plt.plot(result_fpr_L1_arr[i], result_tpr_L1_arr[i], label='C = ' + str(C_list[i]), color=colours[i])
plt.legend(loc='lower right')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve')
plt.grid(True)
plt.show()

log_model_best_L1 = LogisticRegression(solver='liblinear', max_iter=1000, random_state=42, C=1, penalty='l1')
log_model_best_L1.fit(X_train_matrix, y_train)

# Obtain the features and their magnitudes
df_best_features_L1 = pd.DataFrame({'Coefficient':log_model_best_L1.coef_.tolist()[0], 'Feature Name': vectorizer.get_feature_names_out()})
df_best_features_L1['Coef_Magnitude'] = abs(df_best_features_L1['Coefficient'])
df_best_features_L1.sort_values(by='Coef_Magnitude', ascending=False).head(10)











